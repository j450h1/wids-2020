<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Understanding Word Embeddings</title>
    <meta charset="utf-8" />
    <meta name="author" content="Julia Silge" />
    <meta name="date" content="2020-03-13" />
    <link href="libs/remark-css/default.css" rel="stylesheet" />
    <script src="https://use.fontawesome.com/5235085b15.js"></script>
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="css/footer_plus.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">









layout: true

&lt;div class="my-footer"&gt;&lt;span&gt;bit.ly/silge-wids-2020&lt;/span&gt;&lt;/div&gt; 

---

class: inverse, left, middle

background-image: url(figs/patrick-fore-0gkw_9fy0eQ-unsplash.jpg)
background-size: cover

# Understanding 
# Word 
# Embeddings

### Julia Silge | 13 March 2020

---

class: inverse, left, bottom

background-image: url(figs/patrick-fore-0gkw_9fy0eQ-unsplash.jpg)
background-size: cover

# Find me at...

&lt;a href="http://twitter.com/juliasilge" style="color: white;"&gt;&lt;i class="fa fa-twitter fa-fw"&gt;&lt;/i&gt;&amp;nbsp; @juliasilge&lt;/a&gt;&lt;br&gt;
&lt;a href="http://github.com/juliasilge" style="color: white;"&gt;&lt;i class="fa fa-github fa-fw"&gt;&lt;/i&gt;&amp;nbsp; @juliasilge&lt;/a&gt;&lt;br&gt;
&lt;a href="https://juliasilge.com" style="color: white;"&gt;&lt;i class="fa fa-link fa-fw"&gt;&lt;/i&gt;&amp;nbsp; juliasilge.com&lt;/a&gt;&lt;br&gt;
&lt;a href="https://tidytextmining.com" style="color: white;"&gt;&lt;i class="fa fa-book fa-fw"&gt;&lt;/i&gt;&amp;nbsp; tidytextmining.com&lt;/a&gt;&lt;br&gt;
&lt;a href="mailto:julia.silge@gmail.com" style="color: white;"&gt;&lt;i class="fa fa-paper-plane fa-fw"&gt;&lt;/i&gt;&amp;nbsp; julia.silge@gmail.com&lt;/a&gt;

---

class: inverse, center, middle

# ðŸ“‘ TEXT AS DATA ðŸ“Š

---

# Text as data

Let's look at complaints submitted to the [United States Consumer Financial Protection Bureau (CFPB)](https://www.consumerfinance.gov/data-research/consumer-complaints/).


```r
library(tidyverse)

complaints &lt;- read_csv("complaints.csv.gz")
names(complaints)
```

```
## [1] "complaint_id"                 "date_received"                "product"                     
## [4] "issue"                        "company"                      "state"                       
## [7] "consumer_complaint_narrative"
```

---

# Text as data


```r
complaints %&gt;%
  sample_n(10) %&gt;%
  pull(consumer_complaint_narrative)
```

```
##  [1] "See attached documents below, which indicates from a recent dispute and data breach which my information was banking information was all compromised. XXXX has deleted XXXX XXXX from my credit file/credit report as per their investigation. I am requesting for Transunion and XXXX to also delete this fraud account from my credit file as well. I will keep disputing this account as many times needed. As XXXX XXXX is trying to collect moneys not owed and also this account was opened fraudulent which they are already aware. Transunion and XXXX are not complying and slow to respond. As XXXX has already resolved the issue and deleted this file."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                
##  [2] "Hello cfpb, My mortgage has been with CitiMortgage since XX/XX/XXXX &amp; I received a joint letter dated XX/XX/XXXX, from CitiMortgage &amp; XXXX XXXX, stating my mortgage had been sold &amp; to start sending payments to XXXX XXXX, beginning XX/XX/XXXX, which is less than 2 weeks from the date of the letter.\n\nMy complaint is regarding the unprofessional manner I was advised of this sale And who they sold it to.\n\nXXXX XXXX has the most negative reviews for a business that Ive ever seen. Every review about them is negative - not one single positive review.\n\nI am asking cfpd to investigate why they - XXXX XXXX- are still in business &amp; if CitiMorgage can legally advise me of selling my mortgage with this short time-frame notice."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          
##  [3] "EQUIFAX has failed to complete an investigation begun by Equifax in response to CFPB COMPLAINT XXXX regarding XXXX XXXX XXXX, account # XXXX. \nBy function of credit law and procedure this fraudulent account should have been removed from this bureau 's report as it was done on XXXX and XXXX, long ago. \nTHE EQUIFAX REPORT AS ATTACHED SHOWS THIS ACCOUNT '' UNDER INVESTIGATION '' YESTERDAY AFTER CLOSURE OF THE 30 DAY DISPUTE PERIOD begun by the response to the noted CFPB complaint above.EQUIFAX IS NOT HANDLEING THEIR WORKLOAD AND VIOLATES THE FCRA, to my detriment."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          
##  [4] "On XX/XX/19, I applied for an American Express Starwood Preferred Guest credit card with a promotion to earn XXXX points after spending {$3000.00} in 3 months. Under the Offer Terms, it states : \" Welcome offer not available to applicants who have or have had The XXXX XXXX XXXX Credit Card from XXXX, The XXXX XXXX XXXX XXXX Credit Card from XXXX, The XXXX XXXX Credit Card from XXXX, or The XXXX XXXX Credit Card from XXXX XXXX in the last 30 days. '' I haven't had any of these cards in over a year, so I applied. When I received the card I activated it on XX/XX/19 and called to confirm the above referenced promotion. I was told I was ineligible and was told the offer terms were different than what I had recorded when I applied. American Express opened a case to investigate whether I was eligible. \n\nOn XX/XX/19, I spoke with an American Express agent who said the investigation confirmed the wording of the offer terms I originally referenced, but said I was still ineligible, without citing any specific violation. I have not been an account holder of any of the above referenced XXXX accounts in over a year. I was told to submit screenshots of the related account closures with XXXX. An additional investigation was opened and I was told it could take 6 to 8 weeks to resolve. \n\nMeanwhile, the original American Express offer opened for this credit card was to spend {$3000.00} within 3 months of account approval, which will be approximately XX/XX/19 If I wait for the investigation to complete ( 6 to 8 weeks from XX/XX/19 ), I will have passed the deadline to complete the minimum spend and will definitely not be eligible for the bonus promotion. I noted this to the American Express agent on XX/XX/19, and was told the investigation might be finished sooner and I could choose to make the {$3000.00} spend or not."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        
##  [5] "I have paid the same default 3 times. I received the mortgage through divorce. I have sent Ditech my divorce decree, and the Quit claim deed. This company refuses to acknowledge my rights which are the owner of the home. I have been the responsible party of paying this mortgage since I separated from my ex since XX/XX/XXXX. \n\n1st Time -- On XX/XX/XXXX ( I was two months behind on mortgage payment ), I cured a default of {$4000.00}. I submitted an entire payment of {$4700.00} to cure default. Ditech did not allocate money correctly. I submitted a Notice of Error and this company refused to allocate payments correctly which were described in the Default letter. Sent my ex-husband an escrow surplus check of {$1500.00} knowing the default was not cleared. The first time I paid these fees I compiled payments which consisted of 3 money orders, and XXXX XXXX. I kept copies of all payments sent to Ditech, as well as, post office certified mail receipts. \n\n2nd Time -- On XX/XX/XXXX, Ditech sent another cure default letter for the same default out ( 2 months behind on mortgage payment ) for the amount of {$2300.00}. This amount shows clearly the default was not allocated correctly. Ditech put majority of the money in escrow. I submitted a payment of {$2800.00} to clear the same default and Ditech refused again to allocate money correctly. This time I submitted a complaint and Ditech paid on my default and left a balance of {$350.00} -- Corporate Advance Balance, {$130.00} Uncollected NSF Fees, and {$20.00} -- Other Fees. The second time I paid these fees I specified through individual money orders on how all money should have been applied for all fees. When I noticed the money was not applied correctly again, I called Ditech and the representative stated the money would be applied correctly and it never was. I kept copies of all payments sent to Ditech, as well as, post office certified mail receipts. Ditech sent an email stating the money was applied for the XX/XX/XXXX mortgage payment. Ditech still disregarded all labeled XXXX XXXX for cure default fees. \n\n3rd Time -- On XX/XX/XXXX, Ditech sent another cure default letter for the same default out ( 2 months behind on mortgage payment ) for the amount of {$1500.00} As of today, XX/XX/XXXX, I sent Ditech {$1500.00} to cure the default this company will not pay correctly. The third time I paid these fees I through XXXX XXXX, and specified through individual money orders on how all money should have been applied for all fees. I paid Ditech {$1500.00} -- XXXX XXXX, 3 XXXX XXXX -- XXXX ( Late fees ) each, Uncollected NSF Fees -- {$150.00} ( {$20.00} extra by error ) -- Same fees from last time, Other Fees -- {$20.00} -- Same fees as last time, and Corporate Advance Balance -- {$350.00} -- Same fees as last time. My date for right to cure default is XX/XX/XXXX. \n\nWhen the money is received by Ditech, I will owe for XX/XX/XXXX mortgage."
##  [6] "My account with Equifax is locked. I have tried for over 60 days to get it unlocked by calling Equifax at XXXX, as noted on the website. After speaking with 10 different representatives, two of which were supervisors, and having to change my password 9 times, I am still unable to access my account. Supposedly, my issue was elevated to some office three times to get fixed. That hasnt worked. \n\nSince no one to whom I spoke could tell me which headquarters office could assist me, I addressed the issue to Mr. XXXX XXXX, Chief Data and Analytics Officer, on XXXX XX/XX/2019. I stated to him that if his office is not the one who can resolve my issue, please forward my letter to the correct office.I have not received a reply. And my account is still locked."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          
##  [7] "Our attachments have all necessary and pertinent contact information for employees mentioned. \n\nIn XXXX, XXXX, we owed Sears/Citi {$10000.00} for a credit card that was issued to me. We could not make monthly payments due to a serious injury, almost fatal fall, and caring for my mother and a mother-in-law with XXXX. The amount was referred to XXXX XXXX XXXX XXXX who sent a letter to me dated XX/XX/XXXX asking for the balance due. \n\nI called the company and was told by XXXX, XXXX, ext. XXXX, that we could work out a payment settlement. XXXX XXXX XXXX XXXX would automatically withdraw 35 payments of {$280.00} and a 36th payment of {$260.00} that would pay this debt off in three years. We kept our part of the agreement. \n\nXXXX XXXX, XXXX and Sears/Citi then sent a bill and collection letter for an additional {$5200.00} that they said had accrued in interest since XXXX and that we were still liable for this money. We called XXXX XXXX and spoke Mr. XXXX XXXX, Senior Recovery Manager, and explained this. Mr. XXXX said he would file a complaint for us with his company and Sears/Citi. We called Mr. XXXX, Internal Recovery Unit, Citibank, explained the situation to him and have been afforded no solution. We also wrote to both companies XX/XX/XXXX and have received no resolution. We believe XXXX XXXX and Sears/Citibank are working together to collect more money that is not fairly owed them. We keep receiving bills from Sears/Citibank and a new collection letter dated XX/XX/XXXX from Client Services asking for {$4400.00}. \n\nNot wanting to hurt our credit rating any further, we have since paid an additional {$940.00} for which we are asking to be refunded to us. \n\nWe received a letter from Citi, dated XX/XX/XXXX, asking us to call them at XXXX because they \" require more information regarding your recent inquiry '' and when I did, I was told Mr. XXXX XXXX, Vice President, Citibank, N.A., does not take calls. We spoke to Mr. XXXX, again, who said our complaint was denied but we never received anything in writing. If we were denied, then why ask for more information. We have still not received any written correspondence in reply to our letters and phone calls. \n\nWe have been fair to XXXX XXXX XXXX XXXX and Sears/Citibank but we strongly feel they are working together to charge us more than others in the same situation. They have told us how their process works and it is anything but fair."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     
##  [8] "I called Citi bank today and wanted to ask for whether if {$500.00} checking + savings account promotion bonus will be disbursed. I have met all of the required steps to be qualified for the {$500.00} bonus but the call representative said I needed a \" promo code '' for the offer from 3 months back. Mind you, there was no \" promo code '' specified anywhere in their terms and condition page and the only way to apply for the bonus was by clicking \" apply now '' button back then. This is completely unprofessional on citi 's part as they refused to recognize the existence of the promotion even though I have fully satisfy the conditions. This call happened today on XX/XX/19 at XXXX."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  
##  [9] "This loan was originally opened around XX/XX/XXXX. As with another payday loan I have been having problems with paying this loan twice month. On XX/XX/XXXX I withdrew their ACH authorization to withdraw funds from my checking account. I have had to close that account. The payment negotiations they have provided still have twice a month payments. According to my records I have paid {$1600.00} on a {$750.00} loan. I live in Virginia."                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                
## [10] "A hard inquiry was done by XXXX XXXX through Capital One without my consent. I consented for a hard inquiry by XXXX XXXX through XXXX XXXX and I was approved. Capital One has previously done a soft inquiry on my credit and denied me auto finance, so I knew Capital One was not an option for me."
```

---

# Text as data

What is a typical way to represent this text data for modeling?


```r
library(tidytext)
library(SnowballC)

complaints %&gt;% 
  unnest_tokens(word, consumer_complaint_narrative) %&gt;% 
  anti_join(get_stopwords()) %&gt;%  
  mutate(stem = wordStem(word)) %&gt;% 
  count(complaint_id, stem) %&gt;%  
  bind_tf_idf(stem, complaint_id, n) %&gt;% 
  cast_dfm(complaint_id, stem, tf_idf)
```

```
## Document-feature matrix of: 134,423 documents, 49,778 features (99.9% sparse).
##          features
## docs             account       auto       bank        call      charg      chase         dai        date
##   3113204 NA 0.007959449 0.09826659 0.04702513 0.015348248 0.02477143 0.05147568 0.058697715 0.024545160
##   3113208  0 0.001200495 0          0.02127790 0.006944765 0.01868093 0          0           0.003702059
##   3113804  0 0           0          0          0           0          0          0.007053388 0.008848379
##   3113805  0 0.003074285 0          0          0           0          0          0           0          
##   3113807  0 0.034178812 0          0          0           0.05318571 0          0           0          
##   3113808  0 0           0          0          0           0          0          0           0          
##          features
## docs           dollar
##   3113204 0.046369665
##   3113208 0.006993772
##   3113804 0          
##   3113805 0          
##   3113807 0          
##   3113808 0          
## [ reached max_ndoc ... 134,417 more documents, reached max_nfeat ... 49,768 more features ]
```


---

class: inverse, left, bottom

background-image: url(figs/patrick-fore-0gkw_9fy0eQ-unsplash.jpg)
background-size: cover

# This representation...

- .large[is incredibly sparse]
- .large[of high dimensionality]
- .large[with a huge number of features]

---

class: inverse, center, middle

# ðŸ“„ WORD EMBEDDINGS ðŸ“”

---

class: right, middle

&lt;h1 class="fa fa-quote-left fa-fw"&gt;&lt;/h1&gt;

&lt;h1&gt; You shall know a word by the company it keeps. &lt;/h1&gt;

&lt;h1 class="fa fa-quote-right fa-fw"&gt;&lt;/h1&gt;

.large[John Rupert Firth]

---

class: inverse

# Modern word embeddings

--

- word2vec

--

- GloVe

--

- fastText

--

- language models with transformers like ULMFiT and ELMo

---

class: inverse, left, top

background-image: url(figs/patrick-fore-0gkw_9fy0eQ-unsplash.jpg)
background-size: cover

# We can determine word embeddings using...

- .large[word counts]
- .large[matrix factorization]

.footnote[
&lt;a href="https://multithreaded.stitchfix.com/blog/2017/10/18/stop-using-word2vec/" style="color: white"&gt;Moody, Chris. "Stop using word2vec." MultiThreaded blog (2017).&lt;/a&gt;
]

---

# Counting words

First, we tokenize and transform this dataset to a [tidy data structure](https://www.tidytextmining.com/), then create nested dataframes.


```r
tidy_complaints &lt;- complaints %&gt;%
  select(complaint_id, consumer_complaint_narrative) %&gt;%
  unnest_tokens(word, consumer_complaint_narrative) %&gt;%
  group_by(word) %&gt;%
  filter(n() &gt;= 50) %&gt;%
  ungroup()

nested_words &lt;- tidy_complaints %&gt;%
  nest(words = c(word))
```



---

class: inverse

# Sliding window size? ðŸ¤”

--

- Determines semantic meaning the embeddings capture

--

- Smaller window size (3-4) focuses on how the word is used and learns what other words are functionally similar

--

- Larger window size (~10) captures the domain or topic of each word

---

class: inverse

# Point-wise mutual information

--

- How often do words occur on their own?

--

- How often words occur together with other words?

--

- PMI is a measure of association to compute this

--

- PMI is logarithm of the probability of finding two words together, normalized for the probability of finding each of the words alone



---

# Calculate PMI

We use PMI to measure which words occur together more often than expected based on how often they occurred on their own.





```r
library(widyr)
library(furrr)

plan(multiprocess)  ## for parallel processing

tidy_pmi &lt;- nested_words %&gt;%  
  mutate(words = future_map(words, slide_windows, 4)) %&gt;%
  unnest(words) %&gt;%
  unite(window_id, complaint_id, window_id) %&gt;%
  pairwise_pmi(word, window_id)
```

---

# Calculate PMI

When PMI is high, the two words are associated with each other, likely to occur together.


```r
tidy_pmi
```

```
## # A tibble: 5,241,008 x 3
##    item1   item2          pmi
##    &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt;
##  1 systems transworld  7.03  
##  2 inc     transworld  5.87  
##  3 is      transworld  0.0686
##  4 trying  transworld  0.737 
##  5 to      transworld -0.0758
##  6 collect transworld  1.04  
##  7 a       transworld -0.618 
##  8 debt    transworld  0.862 
##  9 that    transworld -0.514 
## 10 not     transworld -1.43  
## # â€¦ with 5,240,998 more rows
```


---

# Time for word vectors! ðŸŽ‰

We determine word vectors using singular value decomposition.


```r
tidy_word_vectors &lt;- tidy_pmi %&gt;%
  widely_svd(
    item1, item2, pmi, 
    nv = 100, maxit = 1000
  )
```

---

class: inverse, left, bottom

### Each word can be represented as a numeric vector in this 

- .large[new,]
- .large[dense,]
- .large[100-dimensional] 

### feature space. 

Which words are close to each other in this new feature space of word embeddings?



---

# Explore CFPB word embeddings


```r
tidy_word_vectors %&gt;%
  nearest_neighbors("error")
```

```
## # A tibble: 7,877 x 2
##    item1      value
##    &lt;chr&gt;      &lt;dbl&gt;
##  1 error     0.0403
##  2 issue     0.0295
##  3 problem   0.0273
##  4 issues    0.0223
##  5 mistake   0.0202
##  6 errors    0.0200
##  7 system    0.0195
##  8 problems  0.0175
##  9 situation 0.0156
## 10 not       0.0142
## # â€¦ with 7,867 more rows
```

---

# Explore CFPB word embeddings


```r
tidy_word_vectors %&gt;%
  nearest_neighbors("month")
```

```
## # A tibble: 7,877 x 2
##    item1     value
##    &lt;chr&gt;     &lt;dbl&gt;
##  1 month    0.0595
##  2 payment  0.0380
##  3 months   0.0356
##  4 days     0.0323
##  5 payments 0.0313
##  6 year     0.0307
##  7 xx       0.0271
##  8 balance  0.0270
##  9 paid     0.0268
## 10 pay      0.0266
## # â€¦ with 7,867 more rows
```

---

# Explore CFPB word embeddings


```r
tidy_word_vectors %&gt;%
  nearest_neighbors("fee")
```

```
## # A tibble: 7,877 x 2
##    item1      value
##    &lt;chr&gt;      &lt;dbl&gt;
##  1 fee       0.0712
##  2 fees      0.0580
##  3 charge    0.0421
##  4 charged   0.0385
##  5 interest  0.0368
##  6 late      0.0342
##  7 charges   0.0335
##  8 overdraft 0.0317
##  9 charging  0.0243
## 10 of        0.0230
## # â€¦ with 7,867 more rows
```

---

# Explore CFPB word embeddings


```r
tidy_word_vectors %&gt;%
  filter(dimension &lt;= 8) %&gt;%
  group_by(dimension) %&gt;%
  top_n(12, abs(value)) %&gt;%
  ungroup %&gt;%
  ggplot(aes(item1, value, fill = as.factor(dimension))) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~dimension, scales = "free_y", ncol = 4) +
  coord_flip()
```

---

![](embeddings_files/figure-html/unnamed-chunk-16-1.png)&lt;!-- --&gt;

---

![](embeddings_files/figure-html/unnamed-chunk-17-1.png)&lt;!-- --&gt;

---

# Embeddings in modeling

The classic and simplest approach is to treat each document as a collection of words and summarize the word embeddings into **document embeddings**.


```r
word_matrix &lt;- tidy_complaints %&gt;% 
  count(complaint_id, word) %&gt;%  
  cast_sparse(complaint_id, word, n)

embedding_matrix &lt;- tidy_word_vectors %&gt;%
  cast_sparse(item1, dimension, value)

doc_matrix &lt;- word_matrix %*% embedding_matrix

dim(doc_matrix)
```

```
## [1] 134379    100
```

---

class: inverse, center, middle

### ðŸ˜­ WHAT IF YOUR DATASET IS TOO SMALL? ðŸ˜©

---

# Try pre-trained word embeddings


```r
library(textdata)

glove6b &lt;- embedding_glove6b(dimensions = 100)
```

---

# Try pre-trained word embeddings


```r
glove6b
```

```
## # A tibble: 400,000 x 101
##    token      d1      d2      d3      d4      d5      d6      d7      d8      d9     d10     d11      d12     d13
##    &lt;chr&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;
##  1 "the" -0.0382 -0.245   0.728  -0.400   0.0832  0.0440 -0.391   0.334  -0.575   0.0875  0.288  -0.0673   0.309 
##  2 ","   -0.108   0.111   0.598  -0.544   0.674   0.107   0.0389  0.355   0.0635 -0.0942  0.158  -0.817    0.142 
##  3 "."   -0.340   0.209   0.463  -0.648  -0.384   0.0380  0.171   0.160   0.466  -0.0192  0.415  -0.343    0.269 
##  4 "of"  -0.153  -0.243   0.898   0.170   0.535   0.488  -0.588  -0.180  -1.36    0.425   0.154   0.242    0.135 
##  5 "to"  -0.190   0.0500  0.191  -0.0492 -0.0897  0.210  -0.550   0.0984 -0.201   0.342  -0.0927  0.161   -0.133 
##  6 "and" -0.0720  0.231   0.0237 -0.506   0.339   0.196  -0.329   0.184  -0.181   0.290   0.204  -0.550    0.274 
##  7 "in"   0.0857 -0.222   0.166   0.134   0.382   0.354   0.0129  0.225  -0.438   0.502  -0.359  -0.350    0.0552
##  8 "a"   -0.271   0.0440 -0.0203 -0.174   0.644   0.712   0.355   0.471  -0.296   0.544  -0.723  -0.00476  0.0406
##  9 "\""  -0.305  -0.236   0.176  -0.729  -0.283  -0.256   0.266   0.0253 -0.0748 -0.377  -0.0578  0.122    0.344 
## 10 "'s"   0.589  -0.202   0.735  -0.683  -0.197  -0.180  -0.392   0.342  -0.606   0.638  -0.267   0.365   -0.404 
## # â€¦ with 399,990 more rows, and 87 more variables: d14 &lt;dbl&gt;, d15 &lt;dbl&gt;, d16 &lt;dbl&gt;, d17 &lt;dbl&gt;, d18 &lt;dbl&gt;,
## #   d19 &lt;dbl&gt;, d20 &lt;dbl&gt;, d21 &lt;dbl&gt;, d22 &lt;dbl&gt;, d23 &lt;dbl&gt;, d24 &lt;dbl&gt;, d25 &lt;dbl&gt;, d26 &lt;dbl&gt;, d27 &lt;dbl&gt;,
## #   d28 &lt;dbl&gt;, d29 &lt;dbl&gt;, d30 &lt;dbl&gt;, d31 &lt;dbl&gt;, d32 &lt;dbl&gt;, d33 &lt;dbl&gt;, d34 &lt;dbl&gt;, d35 &lt;dbl&gt;, d36 &lt;dbl&gt;,
## #   d37 &lt;dbl&gt;, d38 &lt;dbl&gt;, d39 &lt;dbl&gt;, d40 &lt;dbl&gt;, d41 &lt;dbl&gt;, d42 &lt;dbl&gt;, d43 &lt;dbl&gt;, d44 &lt;dbl&gt;, d45 &lt;dbl&gt;,
## #   d46 &lt;dbl&gt;, d47 &lt;dbl&gt;, d48 &lt;dbl&gt;, d49 &lt;dbl&gt;, d50 &lt;dbl&gt;, d51 &lt;dbl&gt;, d52 &lt;dbl&gt;, d53 &lt;dbl&gt;, d54 &lt;dbl&gt;,
## #   d55 &lt;dbl&gt;, d56 &lt;dbl&gt;, d57 &lt;dbl&gt;, d58 &lt;dbl&gt;, d59 &lt;dbl&gt;, d60 &lt;dbl&gt;, d61 &lt;dbl&gt;, d62 &lt;dbl&gt;, d63 &lt;dbl&gt;,
## #   d64 &lt;dbl&gt;, d65 &lt;dbl&gt;, d66 &lt;dbl&gt;, d67 &lt;dbl&gt;, d68 &lt;dbl&gt;, d69 &lt;dbl&gt;, d70 &lt;dbl&gt;, d71 &lt;dbl&gt;, d72 &lt;dbl&gt;,
## #   d73 &lt;dbl&gt;, d74 &lt;dbl&gt;, d75 &lt;dbl&gt;, d76 &lt;dbl&gt;, d77 &lt;dbl&gt;, d78 &lt;dbl&gt;, d79 &lt;dbl&gt;, d80 &lt;dbl&gt;, d81 &lt;dbl&gt;,
## #   d82 &lt;dbl&gt;, d83 &lt;dbl&gt;, d84 &lt;dbl&gt;, d85 &lt;dbl&gt;, d86 &lt;dbl&gt;, d87 &lt;dbl&gt;, d88 &lt;dbl&gt;, d89 &lt;dbl&gt;, d90 &lt;dbl&gt;,
## #   d91 &lt;dbl&gt;, d92 &lt;dbl&gt;, d93 &lt;dbl&gt;, d94 &lt;dbl&gt;, d95 &lt;dbl&gt;, d96 &lt;dbl&gt;, d97 &lt;dbl&gt;, d98 &lt;dbl&gt;, d99 &lt;dbl&gt;,
## #   d100 &lt;dbl&gt;
```



---

# Explore GloVe word embeddings


```r
tidy_glove %&gt;%
  nearest_neighbors("error")
```

```
## # A tibble: 400,000 x 2
##    item1       value
##    &lt;chr&gt;       &lt;dbl&gt;
##  1 error        34.6
##  2 errors       28.1
##  3 data         19.8
##  4 inning       19.4
##  5 game         19.3
##  6 percentage   19.3
##  7 probability  19.2
##  8 unforced     19.1
##  9 fault        19.1
## 10 point        19.0
## # â€¦ with 399,990 more rows
```

---

# Explore GloVe word embeddings


```r
tidy_glove %&gt;%
  nearest_neighbors("month")
```

```
## # A tibble: 400,000 x 2
##    item1     value
##    &lt;chr&gt;     &lt;dbl&gt;
##  1 month      32.4
##  2 year       31.2
##  3 last       30.6
##  4 week       30.5
##  5 wednesday  29.6
##  6 tuesday    29.5
##  7 monday     29.3
##  8 thursday   29.1
##  9 percent    28.9
## 10 friday     28.9
## # â€¦ with 399,990 more rows
```

---

# Explore GloVe word embeddings



```r
tidy_glove %&gt;%
  nearest_neighbors("fee")
```

```
## # A tibble: 400,000 x 2
##    item1        value
##    &lt;chr&gt;        &lt;dbl&gt;
##  1 fee           39.8
##  2 fees          30.7
##  3 pay           26.6
##  4 $             26.4
##  5 salary        25.9
##  6 payment       25.9
##  7 Â£             25.4
##  8 tax           24.9
##  9 payments      23.8
## 10 subscription  23.1
## # â€¦ with 399,990 more rows
```

---

class: inverse, left, bottom

background-image: url(figs/patrick-fore-0gkw_9fy0eQ-unsplash.jpg)
background-size: cover

## Pre-trained word embeddings...

- encode rich semantic relationships

- can be less than ideal for specific tasks

---

class: inverse, left, bottom

background-image: url(figs/patrick-fore-0gkw_9fy0eQ-unsplash.jpg)
background-size: cover

# Fairness and 
# Word 
# Embeddings 

---

# Fairness and word embeddings 

--

- Embeddings are trained or learned from a large corpus of text data

--

- Human prejudice or bias in the corpus becomes imprinted into the embeddings

---

class: inverse

# Fairness and word embeddings 

--

- African American first names are associated with more unpleasant feelings than European American first names

--

- Women's first names are more associated with family and men's first names are more associated with career

--

- Terms associated with women are more associated with the arts and terms associated with men are more associated with science


.footnote[
&lt;a href="https://arxiv.org/abs/1608.07187" style="color: white"&gt;Caliskan, Bryson, and Narayanan. "Semantics Derived Automatically from Language Corpora Contain Human-Like Biases." Science 356.6334 (2017): 183â€“186.&lt;/a&gt;
]

---

&lt;img src="figs/turkish.png" width="322" style="display: block; margin: auto;" /&gt;

---

class: inverse, middle, center

## Bias is so ingrained in word embeddings that they can be used to quantify change in social attitudes over time

.footnote[
&lt;a href="https://www.pnas.org/content/115/16/E3635" style="color: white"&gt;Garg, Nikhil, et al. "Word embeddings quantify 100 years of gender and ethnic stereotypes." Proceedings of the National Academy of Sciences 115.16 (2018): E3635-E3644.&lt;/a&gt;
]

---

# Biased training data 

--

- Embeddings are trained or learned from a large corpus of text data

--

- For example, consider the case of Wikipedia

--

- Wikipedia both reflects social/historical biases **and** generates bias


.footnote[
[Wagner, Claudia, et al. "Women through the glass ceiling: gender asymmetries in Wikipedia." EPJ Data Science 5.1 (2016): 5.](https://link.springer.com/article/10.1140/epjds/s13688-016-0066-4)
]

---

# Biased embeddings in models

Consider a straightforward sentiment analysis model trained to predict how positive text is. **Compare:**

.pull-left[
"Let's go get Italian food!" ðŸ˜Š

]

.pull-right[
"Let's go get Mexican food!" ðŸ˜•
]


.footnote[
[Speer, Robyn. "How to make a racist AI without really trying." ConceptNet blog (2017).](http://blog.conceptnet.io/posts/2017/how-to-make-a-racist-ai-without-really-trying/)
]
---

class: inverse, left, top

background-image: url(figs/patrick-fore-0gkw_9fy0eQ-unsplash.jpg)
background-size: cover

# Consider some options

--

- .large[Find your own embeddings]

--

- .large[Consider not using embeddings]

--

- .large[Can embeddings be debiased?]
---

class: inverse

# Can embeddings be debiased?

--

- Embeddings can be reprojected to mitigate a specific bias (such as gender bias) using specific sets of words

--

- Training data can be augmented with counterfactuals

--

- Other researchers suggest that fairness corrections occur at a decision

--

- Evidence indicates that debiasing still allows stereotypes to seep back in


.footnote[
&lt;a href="https://arxiv.org/abs/1903.03862" style="color: white"&gt;Gonen, Hila, and Yoav Goldberg. "Lipstick on a pig: Debiasing methods cover up systematic gender biases in word embeddings but do not remove them." arXiv preprint arXiv:1903.03862 (2019).&lt;/a&gt;
]

---

class: inverse, left, bottom

background-image: url(figs/patrick-fore-0gkw_9fy0eQ-unsplash.jpg)
background-size: cover

## Word embeddings in the
# REAL WORLD

---

class: inverse, left

background-image: url(figs/patrick-fore-0gkw_9fy0eQ-unsplash.jpg)
background-size: cover

# Thanks!

&lt;a href="http://twitter.com/juliasilge" style="color: white;"&gt;&lt;i class="fa fa-twitter fa-fw"&gt;&lt;/i&gt;&amp;nbsp; @juliasilge&lt;/a&gt;&lt;br&gt;
&lt;a href="http://github.com/juliasilge" style="color: white;"&gt;&lt;i class="fa fa-github fa-fw"&gt;&lt;/i&gt;&amp;nbsp; @juliasilge&lt;/a&gt;&lt;br&gt;
&lt;a href="https://juliasilge.com" style="color: white;"&gt;&lt;i class="fa fa-link fa-fw"&gt;&lt;/i&gt;&amp;nbsp; juliasilge.com&lt;/a&gt;&lt;br&gt;
&lt;a href="https://tidytextmining.com" style="color: white;"&gt;&lt;i class="fa fa-book fa-fw"&gt;&lt;/i&gt;&amp;nbsp; tidytextmining.com&lt;/a&gt;&lt;br&gt;
&lt;a href="mailto:julia.silge@gmail.com" style="color: white;"&gt;&lt;i class="fa fa-paper-plane fa-fw"&gt;&lt;/i&gt;&amp;nbsp; julia.silge@gmail.com&lt;/a&gt;

Slides created with &lt;a href="http://remarkjs.com/" style="color: #5A6B8C;"&gt;&lt;b&gt;remark.js&lt;/b&gt;&lt;/a&gt; and &lt;a href="https://github.com/yihui/xaringan" style="color: #5A6B8C;"&gt;&lt;b&gt;xaringan&lt;/b&gt;&lt;/a&gt;

Photo by &lt;a href="https://unsplash.com/@patrickian4?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" style="color: #5A6B8C;"&gt;&lt;b&gt;Patrick Fore&lt;/b&gt;&lt;/a&gt; on &lt;a href="https://unsplash.com/s/photos/letters?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" style="color: #5A6B8C;"&gt;&lt;b&gt;Unsplash&lt;/b&gt;&lt;/a&gt;
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
